library(qlcMatrix)#
library(qlcRecode)#
#
datafiles <- list.files("../sources/")
ops <- list.files("../orthography profiles")
files <- list.files("../sources/")
files
files <- list.files("../sources/", full.names = TRUE)#
ops <- list.files("../orthography profiles", full.names = TRUE)
data <- read.table(files[1], header = TRUE, sep = "\t", quote = "")
str(data)
head(data)
data <- read.table(files[1], header = TRUE, sep = "\t", quote = "", comment.char = "@")
head(data)
str(data)
paste(data[data[,2]==levels(data[,2][1]),4])
paste(data[data[,2]==levels(data[,2])[1],4])
paste(data[data[,2]==levels(data[,2])[1],4],sep = "; ")
paste(data[data[,2]==levels(data[,2])[1],4],collapse = "; ")
files
ops
tmp <- table(data[,1],data[,2])
max(tmp)
which(tmp==14,arr.ind=T)
which(colSums(tmp)>1)
tmp[tmp>0] <- 1
which(colSums(tmp)>1)
paste(data[data[,2]==levels(data[,2])[8418],4],sep = "; ")
paste(unique(data[data[,2]==levels(data[,2])[8418],4]),collapse = "; ")
head(data)
gsub("fastmowitz2008/","",data[1:10,1])
files[1]
files <- list.files("../sources", full.names = TRUE)
files[1]
convert <- function(source) {#
	datafile <- paste("../sources/", source, ".csv", sep = "")#
	opfile <- paste("../orthography profiles/", source, ".prf", sep = "")#
	data <- read.table(datafile, header = TRUE, sep = "\t", quote = "", comment.char = "@")#
#
	STRING <- as.character(levels(data[,"HEAD"]))#
	TRANSLATION <- sapply(levels(data[,"HEAD"]),function(x) {#
		paste(unique(data[data[,"HEAD"]==x, "TRANSLATION"]),collapse = "; ")#
	})#
#
	PAGE <- sapply(levels(data[,"HEAD"]),function(x) {#
		paste(#
			gsub(source, "", unique(data[data[,"HEAD"]==x, "QLCID"]))#
				, collapse = "; ")#
	})#
#
	STRING <- stri_trans_nfc(STRING)#
	TRANSLATION <- stri_trans_nfc(TRANSLATION)#
	ALIGNMENT <- tokenize(WORDS, opfile, graphemes = "Graphemes", sep = " ")#
#
	n <- length(STRING)#
	SOURCE <- rep(source, times = n)#
	ETYMONID <- rep(0, times = n)#
	LANGUAGE <- rep(data[1,"HEAD_DOCULECT"], times = n)#
	ID <- 1:n#
	result <- cbind(ID,LANGUAGE,SOURCE,PAGE,STRING,TRANSLATION,ALIGNMENT)#
	return(result)#
}
tmp <- convert("fastmowitz2008")
files <- gsub(".csv","",list.files("../sources"))
files
convert <- function(source) {#
	datafile <- paste("../sources/", source, ".csv", sep = "")#
	opfile <- paste("../orthography profiles/", source, ".prf", sep = "")#
	data <- read.table(datafile, header = TRUE, sep = "\t", quote = "", comment.char = "@")#
#
	WORD <- as.character(levels(data[,"HEAD"]))#
	TRANSLATION <- sapply(levels(data[,"HEAD"]),function(x) {#
		paste(unique(data[data[,"HEAD"]==x, "TRANSLATION"]),collapse = "; ")#
	})#
#
	PAGE <- sapply(levels(data[,"HEAD"]),function(x) {#
		paste(#
			gsub(source, "", unique(data[data[,"HEAD"]==x, "QLCID"]))#
				, collapse = "; ")#
	})#
#
	WORD <- stri_trans_nfc(WORD)#
	TRANSLATION <- stri_trans_nfc(TRANSLATION)#
	ALIGNMENT <- tokenize(WORD, opfile, graphemes = "Graphemes", sep = " ")#
#
	n <- length(STRING)#
	SOURCE <- rep(source, times = n)#
	ETYMONID <- rep(0, times = n)#
	LANGUAGE <- rep(data[1,"HEAD_DOCULECT"], times = n)#
	ID <- 1:n#
	result <- cbind(ID,LANGUAGE,SOURCE,PAGE,WORD,TRANSLATION,ALIGNMENT)#
	return(result)#
}
system.time(tmp <- convert("fastmowitz2008"))
convert <- function(source) {#
	datafile <- paste("../sources/", source, ".csv", sep = "")#
	opfile <- paste("../orthography profiles/", source, ".prf", sep = "")#
	data <- read.table(datafile, header = TRUE, sep = "\t", quote = "", comment.char = "@")#
#
	WORD <- as.character(levels(data[,"HEAD"]))#
	TRANSLATION <- sapply(levels(data[,"HEAD"]),function(x) {#
		paste(unique(data[data[,"HEAD"]==x, "TRANSLATION"]),collapse = "; ")#
	})#
#
	PAGE <- sapply(levels(data[,"HEAD"]),function(x) {#
		paste(#
			gsub(source, "", unique(data[data[,"HEAD"]==x, "QLCID"]))#
				, collapse = "; ")#
	})#
#
	WORD <- stri_trans_nfc(WORD)#
	TRANSLATION <- stri_trans_nfc(TRANSLATION)#
	ALIGNMENT <- tokenize(WORD, opfile, graphemes = "Graphemes", sep = " ")#
#
	n <- length(WORD)#
	SOURCE <- rep(source, times = n)#
	ETYMONID <- rep(0, times = n)#
	LANGUAGE <- rep(data[1,"HEAD_DOCULECT"], times = n)#
	result <- cbind(LANGUAGE,SOURCE,PAGE,WORD,TRANSLATION,ALIGNMENT)#
	return(result)#
}
system.time(tmp <- convert("fastmowitz2008"))
head(tmp)
str(data)
as.character(data[1,"HEAD_DOCULECT"])
rownames(tmp) <- NULL
head(tmp)
convert <- function(source) {#
	datafile <- paste("../sources/", source, ".csv", sep = "")#
	opfile <- paste("../orthography profiles/", source, ".prf", sep = "")#
	data <- read.table(datafile, header = TRUE, sep = "\t", quote = "", comment.char = "@")#
#
	WORD <- as.character(levels(data[,"HEAD"]))#
	TRANSLATION <- sapply(levels(data[,"HEAD"]),function(x) {#
		paste(unique(data[data[,"HEAD"]==x, "TRANSLATION"]),collapse = "; ")#
	})#
#
	PAGE <- sapply(levels(data[,"HEAD"]),function(x) {#
		paste(#
			gsub(source, "", unique(data[data[,"HEAD"]==x, "QLCID"]))#
				, collapse = "; ")#
	})#
#
	WORD <- stri_trans_nfc(WORD)#
	TRANSLATION <- stri_trans_nfc(TRANSLATION)#
	ALIGNMENT <- tokenize(WORD, opfile, graphemes = "Graphemes", sep = " ")#
#
	n <- length(WORD)#
	SOURCE <- rep(source, times = n)#
	ETYMONID <- rep(0, times = n)#
	LANGUAGE <- rep(as.character(data[1,"HEAD_DOCULECT"]), times = n)#
	result <- cbind(LANGUAGE,SOURCE,PAGE,WORD,TRANSLATION,ALIGNMENT)#
	rownames(result) <- NULL#
	return(result)#
}
system.time(tmp <- convert("fastmowitz2008"))
head(tmp)
?do.apply
?apply.de
?apply
convert <- function(source) {#
	datafile <- paste("../sources/", source, ".csv", sep = "")#
	opfile <- paste("../orthography profiles/", source, ".prf", sep = "")#
	data <- read.table(datafile, header = TRUE, sep = "\t", quote = "", comment.char = "@")#
#
	WORD <- as.character(levels(data[,"HEAD"]))#
	TRANSLATION <- sapply(levels(data[,"HEAD"]),function(x) {#
		paste(unique(data[data[,"HEAD"]==x, "TRANSLATION"]),collapse = "; ")#
	})#
#
	PAGE <- sapply(levels(data[,"HEAD"]),function(x) {#
		paste(#
			gsub(source, "", unique(data[data[,"HEAD"]==x, "QLCID"]))#
				, collapse = "; ")#
	})#
#
	WORD <- stri_trans_nfc(WORD)#
	TRANSLATION <- stri_trans_nfc(TRANSLATION)#
	ALIGNMENT <- tokenize(WORD, opfile, graphemes = "Graphemes", sep = " ")#
#
	n <- length(WORD)#
	SOURCE <- rep(source, times = n)#
	ETYMONID <- rep(0, times = n)#
	LANGUAGE <- rep(as.character(data[1,"HEAD_DOCULECT"]), times = n)#
	result <- cbind(LANGUAGE,SOURCE,PAGE,WORD,ETYMONID,ALIGNMENT,TRANSLATION)#
	rownames(result) <- NULL#
	return(result)#
}#
#
# =============#
#
files <- gsub(".csv","",list.files("../sources"))#
all <- sapply(files,convert)#
joined <- do.call(rbind, all)#
ID <- 1:dim(joined)[1]#
joined <- cbind(ID,joined)
rd <- function(source) {#
	datafile <- paste("../sources/", source, ".csv", sep = "")#
	data <- read.table(datafile, header = TRUE, sep = "\t", quote = "", comment.char = "@")#
	return(data)#
}
tmp <- rd(files[1])
tmp <- rd(files[2])
tmp <- rd(files[3])
tmp <- rd(files[4])
write.orthography.profile(tmp[,2])
tokenize("asdf,asdf","../orthography profiles/mori1981.csv")
tokenize("asdf asdf","../orthography profiles/mori1981.csv",graphemes="Graphemes")
tokenize("asdf asdf","../orthography profiles/mori1981.csv",graphemes="Graphemes",sep=" ")
tokenize("asdf asdf","../orthography profiles/mori1981.csv",graphemes="Graphemes",sep=" ",boundary=" ")
tokenize("asdfasdf","../orthography profiles/mori1981.csv",graphemes="Graphemes",sep=" ",boundary=" ")
?tokenize
# produce statistics#
example <- "nana änngschä ach"#
write.orthography.profile(example)#
#
# make a better orthography profile#
gr <- cbind(c("a","ä","n","ng","ch","sch"),c("a","e","n","N","x","sh"))#
colnames(gr) <- c("graphemes","replace")#
( op <- list(graphs = gr, rules = NULL) )#
#
# tokenization#
tokenize("nana änngschä ach", op, graphemes = "graphemes")#
# with replacements and an error message#
tokenize("Naná änngschä ach", op, graphemes = "graphemes", replace = "replace")
tokenize("asdfasdf","../orthography profiles/mori1981.prf",graphemes="Graphemes",sep=" ",boundary=" ")
tokenize("asd asd ","../orthography profiles/mori1981.prf",graphemes="Graphemes",sep=" ",boundary=" ")
tmp <- rd(files[4])
tmp <- rd(files[5])
tmp <- rd(files[6])
files <- gsub(".csv","",list.files("../sources"))#
all <- sapply(files,convert)#
joined <- do.call(rbind, all)#
ID <- 1:dim(joined)[1]#
joined <- cbind(ID,joined)
dim(joined)
head(joined)
joined[10000,]
joined <- gsub("Humabisa","Huambisa",joined)
joined[10000:10005,]
joined[20000:20005,]
joined[30000:30005,]
write.table(joined,"../data.tsv",sep="\t",row.names=F,quote=F)
dim(joined)
library(qlcRecode)#
#
convert <- function(source) {#
	datafile <- paste("../sources/", source, ".csv", sep = "")#
	opfile <- paste("../orthography profiles/", source, ".prf", sep = "")#
	data <- read.table(datafile, header = TRUE, sep = "\t", quote = "", comment.char = "@")#
#
	WORD <- as.character(levels(data[,"HEAD"]))#
	TRANSLATION <- sapply(levels(data[,"HEAD"]),function(x) {#
		paste(unique(data[data[,"HEAD"]==x, "TRANSLATION"]),collapse = "; ")#
	})#
#
	PAGE <- sapply(levels(data[,"HEAD"]),function(x) {#
		paste(#
			gsub(source, "", unique(data[data[,"HEAD"]==x, "QLCID"]))#
				, collapse = "; ")#
	})#
#
	WORD <- stri_trans_nfc(WORD)#
	TRANSLATION <- stri_trans_nfc(TRANSLATION)#
	ALIGNMENT <- tokenize(WORD, opfile, graphemes = "Graphemes", sep = " ")#
#
	n <- length(WORD)#
	SOURCE <- rep(source, times = n)#
	ETYMONID <- rep(0, times = n)#
	LANGUAGE <- rep(as.character(data[1,"HEAD_DOCULECT"]), times = n)#
	result <- cbind(LANGUAGE,SOURCE,PAGE,WORD,ETYMONID,ALIGNMENT,TRANSLATION)#
	rownames(result) <- NULL#
	return(result)#
}#
#
# =============#
#
files <- gsub(".csv","",list.files("../sources"))
files
tmp <- convert(files[7])
head(tmp)
tail(tmp)
grep("#",tmp[,"ALIGNMENT"])
tmp[91,]
tmp[c(91,93),]
files <- gsub(".csv","",list.files("../sources"))#
all <- sapply(files,convert)#
joined <- do.call(rbind, all)#
ID <- 1:dim(joined)[1]#
joined <- cbind(ID,joined)#
#
write.table(joined,"../data.tsv",sep="\t",row.names=F,quote=F)
